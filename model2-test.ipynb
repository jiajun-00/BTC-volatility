{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import statistics\n",
    "#from function import *\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from btbase import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test class\n",
    "# 可以模拟真实市场来判断阶数的选择\n",
    "class test:\n",
    "    \n",
    "    # 初始化\n",
    "    # dataframe: 本地dataframe\n",
    "    # data_laundry: 所有在t时间用到的数据（包括error项） 以及真实的volatility和预测的volatility\n",
    "    # start_time: 数据开始时间\n",
    "    # end_time: 数据结束时间\n",
    "    # data_record: 在t时间用到的数据（不包括error项）不包括真实的volatility和预测的volatility （缩短拟合时间）\n",
    "    def __init__(self):\n",
    "        self.dataframe = None\n",
    "        self.data_laundry = None\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.data_record = None\n",
    "    \n",
    "    # 通过平台api获取数据\n",
    "    def set_data(self, s_time, e_time, symbols='btc/usdt.spot.binance', fields=None, bar_type=\"1m\", offset=None, engine_info=None):\n",
    "        # 获取数据api\n",
    "        self.dataframe = get_crypto_price(s_time, e_time, symbols=symbol_, fields=None, bar_type=\"1m\", offset=None, engine_info=None)\n",
    "        # 把收益率加入到dataframe中\n",
    "        self.dataframe = self.dataframe.assign(return_close= self.dataframe['close'].pct_change() * 100)\n",
    "        # 获取数据的开始时间\n",
    "        self.start_time = self.dataframe['e_date'].iloc[0]\n",
    "        # 获取数据的结束时间\n",
    "        self.end_time = self.dataframe['e_date'].iloc[-1]\n",
    "    \n",
    "    # 通过dataframe文件获取数据\n",
    "    def set_data_df(self, dataframe):\n",
    "        # 本地dataframe\n",
    "        self.dataframe = dataframe  \n",
    "        # 把收益率加入到dataframe中 \n",
    "        self.dataframe = self.dataframe.assign(return_close= self.dataframe['close'].pct_change() * 100) \n",
    "        # 获取数据的开始时间\n",
    "        self.start_time = self.dataframe['e_date'].iloc[0] \n",
    "        # 获取数据的结束时间\n",
    "        self.end_time = self.dataframe['e_date'].iloc[-1]\n",
    "        \n",
    "    \n",
    "    # 方程用来得到相应步长的volatility^2\n",
    "    # 结果是顺序的dataframe包含每个以小时为单位的区间volatility^2\n",
    "    def get_volatility(self, time_step):\n",
    "        # 倒序向前60分钟 作为每个区间的endtime\n",
    "        time_range = pd.date_range(start=self.end_time , end=self.start_time, freq = timedelta(minutes = -60))\n",
    "        # 建立dataframe\n",
    "        hour_table = pd.DataFrame({'hour_e_time': time_range})\n",
    "        # 根据time_step确定每个区间长度\n",
    "        hour_table.insert(0, 'hour_s_time' , time_range + timedelta(minutes = - time_step))\n",
    "        volatility = []\n",
    "        # 在dataframe中取出相应区间的收益率并计算标准差得到volatility\n",
    "        for i in hour_table.index:\n",
    "            volatility.append(np.var(self.dataframe['return_close'][(self.dataframe.e_date > hour_table.hour_s_time[i]) & (self.dataframe.e_date <=  hour_table.hour_e_time[i])].dropna()))\n",
    "        # 加入dataframe\n",
    "        hour_table['volatility'] = volatility\n",
    "        # 换成顺序排列\n",
    "        return hour_table.dropna()[::-1].reset_index(drop=True)\n",
    "    \n",
    "    # 相应步长内最高和最低值的差值\n",
    "    # 结果是顺序的dataframe包含每个以小时为单位的区间high和low的差值\n",
    "    def get_maximum_highlow_difference(self, time_step):\n",
    "        # 倒序向前60分钟 作为每个区间的endtime\n",
    "        time_range = pd.date_range(start=self.end_time , end=self.start_time, freq = timedelta(minutes = -60))\n",
    "        hour_table = pd.DataFrame({'hour_e_time': time_range})\n",
    "        # 根据time_step确定每个区间长度\n",
    "        # 这样就可以得到每个区间的starttime 区间长度为time_step\n",
    "        hour_table.insert(0, 'hour_s_time' , time_range + timedelta(minutes = - time_step))\n",
    "\n",
    "        difference = []\n",
    "        # 在dataframe中取出相应区间的最高和最低值做差\n",
    "        for i in hour_table.index:\n",
    "            # 根据hour_table的starttime和endtime取出相应的dataframe\n",
    "            df_curr = self.dataframe[(self.dataframe.e_date > hour_table.hour_s_time[i]) & (self.dataframe.e_date <=  hour_table.hour_e_time[i])]\n",
    "            # 取出最高和最低值\n",
    "            high = max(df_curr['high'].dropna())\n",
    "            low = min(df_curr['low'].dropna())\n",
    "            difference.append(high - low)\n",
    "        # 加入dataframe\n",
    "        hour_table['highlow_difference'] = difference\n",
    "        # 换成顺序排列\n",
    "        return hour_table.dropna()[::-1].reset_index(drop=True)      \n",
    "    \n",
    "    \n",
    "    # 相应步长内每分钟high和low的差值的标准差\n",
    "    # 结果是顺序的dataframe包含每个以小时为单位的区间high和low的差值的sum\n",
    "    def get_highlow(self, time_step):\n",
    "        # 倒序向前60分钟 作为每个区间的endtime\n",
    "        time_range = pd.date_range(start=self.end_time , end=self.start_time, freq = timedelta(minutes = -60))\n",
    "        hour_table = pd.DataFrame({'hour_e_time': time_range})\n",
    "        # 根据time_step确定每个区间长度\n",
    "        # 这样就可以得到每个区间的starttime 区间长度为time_step\n",
    "        hour_table.insert(0, 'hour_s_time' , time_range + timedelta(minutes = - time_step))\n",
    "\n",
    "        highlow = []\n",
    "        # 在dataframe中取出相应区间的high和low的差值并计算sim得到\n",
    "        for i in hour_table.index:\n",
    "            # 根据hour_table的starttime和endtime取出相应的dataframe\n",
    "            df_curr = self.dataframe[(self.dataframe.e_date > hour_table.hour_s_time[i]) & (self.dataframe.e_date <=  hour_table.hour_e_time[i])]\n",
    "            highlow.append(np.sum(df_curr['high'] - df_curr['low']))\n",
    "\n",
    "        # 加入dataframe\n",
    "        hour_table['highlow'] = highlow\n",
    "        # 换成顺序排列\n",
    "        return hour_table.dropna()[::-1].reset_index(drop=True)  \n",
    "    \n",
    "    # 计算每个区间volume_sum\n",
    "    # 结果是顺序的dataframe包含每个以小时为单位的区间volume_sum\n",
    "    def get_volume_sum(self, time_step):\n",
    "        # 倒序向前60分钟 作为每个区间的endtime\n",
    "        time_range = pd.date_range(start=self.end_time , end=self.start_time, freq = timedelta(minutes = -60))\n",
    "        hour_table = pd.DataFrame({'hour_e_time': time_range})\n",
    "        # 根据time_step确定每个区间长度\n",
    "        # 这样就可以得到每个区间的starttime 区间长度\n",
    "        hour_table.insert(0, 'hour_s_time' , time_range + timedelta(minutes = - time_step))\n",
    "\n",
    "        volume_sum = []\n",
    "        # 在dataframe中取出相应区间的high和low的差值并计算标准差得到\n",
    "        for i in hour_table.index:\n",
    "            # 根据hour_table的starttime和endtime取出相应的dataframe\n",
    "            df_curr = self.dataframe[(self.dataframe.e_date > hour_table.hour_s_time[i]) & (self.dataframe.e_date <=  hour_table.hour_e_time[i])]\n",
    "            volume_sum.append(np.sum(df_curr['volume']))\n",
    "        \n",
    "        # 加入dataframe\n",
    "        hour_table['volume_sum'] = volume_sum\n",
    "        # 换成顺序排列\n",
    "        return hour_table.dropna()[::-1].reset_index(drop=True)  \n",
    "\n",
    "    # 计算每个区间头尾的收益率的平方(Rt^2)\n",
    "    # Rt = (Pt - Pt-1)/Pt-1\n",
    "    # 这里t以timestep为单位\n",
    "    def get_return_square(self, time_step):\n",
    "        # 倒序向前60分钟 作为每个区间的endtime\n",
    "        time_range = pd.date_range(start=self.end_time , end=self.start_time, freq = timedelta(minutes = -60))\n",
    "        hour_table = pd.DataFrame({'hour_e_time': time_range})\n",
    "        # 根据time_step确定每个区间长度\n",
    "        hour_table.insert(0, 'hour_s_time' , time_range + timedelta(minutes = - time_step))\n",
    "        \n",
    "        return_square = []\n",
    "        # 在dataframe中取出相应区间的high和low的差值并计算标准差得到\n",
    "        for i in hour_table.index:\n",
    "            # 根据hour_table的starttime和endtime取出相应的dataframe\n",
    "            close = self.dataframe['close'][(self.dataframe.e_date > hour_table.hour_s_time[i]) & (self.dataframe.e_date <=  hour_table.hour_e_time[i])].dropna()\n",
    "            # Rt^2 = ((Pt - Pt-1)/Pt-1)^2\n",
    "            return_square.append(((close.values[0] - close.values[-1] )/ close.values[0])**2)\n",
    "            #return_square.append((np.log(close.values[0]/close.values[-1]))**2)\n",
    "\n",
    "        # 加入dataframe\n",
    "        hour_table['return_square'] = return_square\n",
    "        # 换成顺序排列\n",
    "        return hour_table.dropna()[::-1].reset_index(drop=True)\n",
    "    \n",
    "    # 计算每个区间volume_sum的zscore\n",
    "    # zscore = (x - mean(x))/std(x)\n",
    "    # 这里mean(x)是每个period内的volume_sum的均值 period用小时作为单位\n",
    "    # std(x)是每个period内的volume_sum的标准差\n",
    "    # x是每个time_step内的volume_sum\n",
    "    def get_zscore(self, time_step, period):\n",
    "        # 得到每个time_step的volume_sum\n",
    "        original = self.get_volume_sum(time_step)\n",
    "        zscore = []\n",
    "        \n",
    "        # 倒序向前60分钟 作为每个区间的endtime\n",
    "        time_range = pd.date_range(start=self.end_time , end=self.start_time, freq = timedelta(minutes = -60))\n",
    "        hour_table = pd.DataFrame({'hour_e_time': time_range})\n",
    "        # 根据period确定每个mean和std范围\n",
    "        hour_table.insert(0, 'hour_s_period' , time_range + timedelta(hours = - period))  \n",
    "        \n",
    "        # 删除最后一个区间\n",
    "        # 因为最后一个区间的数据是不完整的\n",
    "        hour_table = hour_table.iloc[:-period]\n",
    "        \n",
    "        # 计算zscore\n",
    "        for i in hour_table.index:\n",
    "            # 取出相应区间的volume_sum\n",
    "            df_curr = original[(original.hour_e_time > hour_table.hour_s_period[i]) & (original.hour_e_time <=  hour_table.hour_e_time[i])]\n",
    "            zscore.append((df_curr['volume_sum'].iloc[-1] - np.mean(df_curr['volume_sum']))/np.std(df_curr['volume_sum']))\n",
    "        \n",
    "        # 加入dataframe\n",
    "        hour_table['zscore'] = zscore\n",
    "        \n",
    "        # 换成顺序排列\n",
    "        return hour_table.dropna()[::-1].reset_index(drop=True)    \n",
    "\n",
    "    # 得到模型\n",
    "    # 如果有moving average 则返回两个模型\n",
    "    # order: 每个变量的阶数\n",
    "    # order[0]: highlow_difference\n",
    "    # order[1]: highlow\n",
    "    # order[2]: volume_sum\n",
    "    # order[3]: return_square\n",
    "    # order[4]: volatility\n",
    "    # order[5]: zscore\n",
    "    # timestep: 每个变量的时间步长 这里timestep[5]是一个list 第一个是zscore的时间步长 第二个是zscore的period\n",
    "    # ma: moving average的阶数\n",
    "    # 模型是volatility = a0 + b(n)*highlow_difference(t-n) + c(n)*highlow(t-n) + d(n)*volume_sum(t-n) + e(n)*return_square(t-n) + f(n)*volatility(t-n) + g(n)*zscore(t-n) + h(n)*error(t-n) + error\n",
    "    def HLVGARCH_MA(self, order = [1, 1, 1, 1, 1, 1], timestep = [60, 60, 60, 60, 60, [60, 24]], ma = 0):\n",
    "        # 倒序向前60分钟 作为每个区间的endtime\n",
    "        # 区间长度是60分钟\n",
    "        time_range = pd.date_range(start=self.end_time , end=self.start_time, freq = timedelta(minutes = -60))\n",
    "        self.data_laundry = pd.DataFrame({'hour_e_time': time_range})\n",
    "        self.data_laundry.insert(0, 'hour_s_time' , time_range + timedelta(minutes = - 60))\n",
    "\n",
    "        # 换成顺序排列\n",
    "        self.data_laundry = self.data_laundry.dropna()[::-1].reset_index(drop=True)\n",
    "        \n",
    "        # 得到volatility\n",
    "        dataframe_volatility_real = self.get_volatility(60).drop(columns = ['hour_s_time'])\n",
    "        \n",
    "        # 把真实的volatility加入到dataframe中\n",
    "        self.data_laundry = self.data_laundry.merge(dataframe_volatility_real, on = 'hour_e_time', how = 'inner')\n",
    "        \n",
    "        # highlow_difference（t-n） n为order[0]的阶数\n",
    "        if order[0] >0:\n",
    "            # 得到每个时段的highlow_difference\n",
    "            dataframe_highlow_diff = self.get_maximum_highlow_difference(timestep[0]).drop(columns = ['hour_s_time'])\n",
    "            for i in range(order[0]):\n",
    "                # shift i+1 个单位\n",
    "                # 以此得到t-1, t-2, t-3。。。的highlow_difference\n",
    "                dataframe_highlow_diff['highlow_difference_t' + str(i)] = dataframe_highlow_diff['highlow_difference'].shift(i+1)  \n",
    "            # 根据endtime合并 dataframe    \n",
    "            self.data_laundry = self.data_laundry.merge(dataframe_highlow_diff.drop(columns = ['highlow_difference']), on = 'hour_e_time', how = 'inner')\n",
    "        \n",
    "        # highlow（t-n） n为order[1]的阶数\n",
    "        if order[1] >0:\n",
    "            # 得到每个时段的highlow\n",
    "            dataframe_highlow = self.get_highlow(timestep[1]).drop(columns = ['hour_s_time'])\n",
    "            for i in range(order[1]):\n",
    "                # shift i+1 个单位\n",
    "                # 以此得到t-1, t-2, t-3。。。的highlow\n",
    "                dataframe_highlow['highlow_t' + str(i)] = dataframe_highlow['highlow'].shift(i+1)\n",
    "            # 根据endtime合并 dataframe    \n",
    "            self.data_laundry = self.data_laundry.merge(dataframe_highlow.drop(columns = ['highlow']), on = 'hour_e_time', how = 'inner')\n",
    "        \n",
    "        # volume_sum（t-n） n为order[2]的阶数\n",
    "        if order[2] >0:\n",
    "            # 得到每个时段的volume_sum\n",
    "            dataframe_volume_sum = self.get_volume_sum(timestep[2]).drop(columns = ['hour_s_time'])\n",
    "            for i in range(order[2]):\n",
    "                # shift i+1 个单位\n",
    "                # 以此得到t-1, t-2, t-3。。。的volume_sum\n",
    "                dataframe_volume_sum['volume_sum_t' + str(i)] = dataframe_volume_sum['volume_sum'].shift(i+1)\n",
    "            # 根据endtime合并 dataframe    \n",
    "            self.data_laundry = self.data_laundry.merge(dataframe_volume_sum.drop(columns = ['volume_sum']), on = 'hour_e_time', how = 'inner')\n",
    "\n",
    "        if order[3] >0:\n",
    "            # 得到每个时段的return_square\n",
    "            dataframe_return_square = self.get_return_square(timestep[3]).drop(columns = ['hour_s_time'])\n",
    "            for i in range(order[3]):\n",
    "                # shift i+1 个单位\n",
    "                # 以此得到t-1, t-2, t-3。。。的return_square\n",
    "                dataframe_return_square['return_square_t' + str(i)] = dataframe_return_square['return_square'].shift(i+1)\n",
    "            # 根据endtime合并 dataframe    \n",
    "            self.data_laundry = self.data_laundry.merge(dataframe_return_square.drop(columns = ['return_square']), on = 'hour_e_time', how = 'inner')\n",
    "        \n",
    "        if order[4] >0:\n",
    "            # 得到每个时段的volatility\n",
    "            dataframe_volatility = self.get_volatility(timestep[4]).drop(columns = ['hour_s_time'])\n",
    "            for i in range(order[4]):\n",
    "                # shift i+1 个单位\n",
    "                # 以此得到t-1, t-2, t-3。。。的volatility\n",
    "                dataframe_volatility['volatility_t' + str(i)] = dataframe_volatility['volatility'].shift(i+1)\n",
    "            # 根据endtime合并 dataframe    \n",
    "            self.data_laundry = self.data_laundry.merge(dataframe_volatility.drop(columns = ['volatility']), on = 'hour_e_time', how = 'inner')\n",
    "        \n",
    "        if order[5] >0:\n",
    "            # 得到每个时段的volatility\n",
    "            dataframe_volatility = self.get_volatility(timestep[5]).drop(columns = ['hour_s_time'])\n",
    "            for i in range(order[5]):\n",
    "                # shift i+1 个单位\n",
    "                # 以此得到t-1, t-2, t-3。。。的volatility\n",
    "                dataframe_volatility['volatility2_t' + str(i)] = dataframe_volatility['volatility'].shift(i+1)\n",
    "            # 根据endtime合并 dataframe    \n",
    "            self.data_laundry = self.data_laundry.merge(dataframe_volatility.drop(columns = ['volatility']), on = 'hour_e_time', how = 'inner')   \n",
    "        \n",
    "        # 删除缺失值 对其数据\n",
    "        self.data_laundry = self.data_laundry.dropna()\n",
    "       \n",
    "        # 真实的volatility 用来拟合\n",
    "        Y = self.data_laundry['volatility']\n",
    "        # 除了volatility的其他数据 用来作为自变量\n",
    "        X = self.data_laundry.drop(columns = ['hour_e_time', 'hour_s_time', 'volatility'])\n",
    "        \n",
    "        # 拟合模型 加上截距\n",
    "        model = [sm.OLS(Y, sm.add_constant(X)).fit()]\n",
    "        \n",
    "        # 把预测volatility加入到dataframe中\n",
    "        self.data_laundry['predict_volatility'] = model[0].predict(sm.add_constant(X))\n",
    "        \n",
    "        # 加入真实volatility\n",
    "        self.data_laundry['volatility'] = self.data_laundry['volatility']\n",
    "        \n",
    "        # 如果有moving average\n",
    "        if ma > 0:\n",
    "            # 计算误差\n",
    "            self.data_laundry['error'] = self.data_laundry['volatility'] - self.data_laundry['predict_volatility']\n",
    "            # 得到t-1, t-2, t-3。。。的误差\n",
    "            for i in range(ma):\n",
    "                self.data_laundry['error_t' + str(i)] = self.data_laundry['error'].shift(i+1)\n",
    "            \n",
    "            # 删除缺失值\n",
    "            self.data_laundry = self.data_laundry.dropna()\n",
    "            # 真实的volatility 用来拟合\n",
    "            Y = self.data_laundry['volatility']\n",
    "            # 除了volatility的其他数据 用来作为自变量\n",
    "            X = self.data_laundry.drop(columns = ['hour_e_time', 'hour_s_time', 'volatility', 'predict_volatility', 'error'])\n",
    "            # 拟合模型\n",
    "            model.append(sm.OLS(Y, sm.add_constant(X)).fit()) \n",
    "            self.data_laundry = self.data_laundry.drop(columns = ['error'])   \n",
    "        \n",
    "        # 加入真实volatility和预测volatility\n",
    "        self.data_laundry['real'] = self.data_laundry['volatility']\n",
    "        self.data_laundry['predict'] = model[-1].predict(sm.add_constant(X))\n",
    "        \n",
    "        # 删除不需要的数据\n",
    "        self.data_laundry = self.data_laundry.drop(columns = [ 'volatility', 'predict_volatility'])\n",
    "\n",
    "        # 返回模型\n",
    "        return model\n",
    "    \n",
    "    # data record主要是用来方便滚动预测提取数据 减少拟合时间\n",
    "    # 输入order和timestep 就可以得到相应每个时段的数据\n",
    "    # highlow_difference(t-n)  highlow(t-n)  volume_sum(t-n)  return_square(t-n)  volatility(t-n)  zscore(t-n)   t \n",
    "    def set_data_record(self, order, timestep):\n",
    "        # 倒序向前60分钟 作为每个区间的endtime\n",
    "        time_range = pd.date_range(start=self.end_time , end=self.start_time, freq = timedelta(minutes = -60))\n",
    "        # 建立dataframe\n",
    "        self.data_record = pd.DataFrame({'hour_e_time': time_range})\n",
    "        # 根据time_step确定每个区间长度\n",
    "        self.data_record.insert(0, 'hour_s_time' , time_range + timedelta(minutes = - 60))\n",
    "        # 换成顺序排列\n",
    "        self.data_record = self.data_record.dropna()[::-1].reset_index(drop=True)\n",
    "        \n",
    "        # 得到volatility\n",
    "        dataframe_volatility_real = self.get_volatility(60).drop(columns = ['hour_s_time'])\n",
    "        \n",
    "        # 把真实的volatility加入到dataframe中\n",
    "        self.data_record = self.data_record.merge(dataframe_volatility_real, on = 'hour_e_time', how = 'inner')\n",
    "\n",
    "        if order[0] >0:\n",
    "            # 得到每个时段的highlow_difference\n",
    "            dataframe_highlow_diff = self.get_maximum_highlow_difference(timestep[0]).drop(columns = ['hour_s_time'])\n",
    "            for i in range(order[0]):\n",
    "                # shift i+1 个单位\n",
    "                # 以此得到t-1, t-2, t-3。。。的highlow_difference\n",
    "                dataframe_highlow_diff['highlow_difference_t' + str(i)] = dataframe_highlow_diff['highlow_difference'].shift(i+1)  \n",
    "            # 根据endtime合并 dataframe    \n",
    "            self.data_record = self.data_record.merge(dataframe_highlow_diff.drop(columns = ['highlow_difference']), on = 'hour_e_time', how = 'inner')\n",
    "        \n",
    "        if order[1] >0:\n",
    "            # 得到每个时段的highlow\n",
    "            dataframe_highlow = self.get_highlow(timestep[1]).drop(columns = ['hour_s_time'])\n",
    "            for i in range(order[1]):\n",
    "                # shift i+1 个单位\n",
    "                # 以此得到t-1, t-2, t-3。。。的highlow\n",
    "                dataframe_highlow['highlow_t' + str(i)] = dataframe_highlow['highlow'].shift(i+1)\n",
    "            # 根据endtime\n",
    "            self.data_record = self.data_record.merge(dataframe_highlow.drop(columns = ['highlow']), on = 'hour_e_time', how = 'inner')\n",
    "        \n",
    "        if order[2] >0:\n",
    "            # 得到每个时段的volume_sum\n",
    "            dataframe_volume_sum = self.get_volume_sum(timestep[2]).drop(columns = ['hour_s_time'])\n",
    "            for i in range(order[2]):\n",
    "                # shift i+1 个单位\n",
    "                # 以此得到t-1, t-2, t-3。。。的volume_sum\n",
    "                dataframe_volume_sum['volume_sum_t' + str(i)] = dataframe_volume_sum['volume_sum'].shift(i+1)\n",
    "            # 根据endtime合并 dataframe    \n",
    "            self.data_record = self.data_record.merge(dataframe_volume_sum.drop(columns = ['volume_sum']), on = 'hour_e_time', how = 'inner')\n",
    "        \n",
    "        if order[3] >0:\n",
    "            # 得到每个时段的return_square\n",
    "            dataframe_return_square = self.get_return_square(timestep[3]).drop(columns = ['hour_s_time'])\n",
    "            for i in range(order[3]):\n",
    "                # shift i+1 个单位\n",
    "                # 以此得到t-1, t-2, t-3。。。的return_square\n",
    "                dataframe_return_square['return_square_t' + str(i)] = dataframe_return_square['return_square'].shift(i+1)\n",
    "            # 根据endtime合并 dataframe    \n",
    "            self.data_record = self.data_record.merge(dataframe_return_square.drop(columns = ['return_square']), on = 'hour_e_time', how = 'inner')\n",
    "        \n",
    "        if order[4] >0:\n",
    "            # 得到每个时段的volatility\n",
    "            dataframe_volatility = self.get_volatility(timestep[4]).drop(columns = ['hour_s_time'])\n",
    "            for i in range(order[4]):\n",
    "                # shift i+1 个单位\n",
    "                # 以此得到t-1, t-2, t-3。。。的volatility\n",
    "                dataframe_volatility['volatility_t' + str(i)] = dataframe_volatility['volatility'].shift(i+1)\n",
    "            # 根据endtime合并 dataframe    \n",
    "            self.data_record = self.data_record.merge(dataframe_volatility.drop(columns = ['volatility']), on = 'hour_e_time', how = 'inner')\n",
    "        \n",
    "        if order[5] >0:\n",
    "            # 得到每个时段的volatility\n",
    "            dataframe_volatility = self.get_volatility(timestep[5]).drop(columns = ['hour_s_time'])\n",
    "            for i in range(order[5]):\n",
    "                # shift i+1 个单位\n",
    "                # 以此得到t-1, t-2, t-3。。。的volatility\n",
    "                dataframe_volatility['volatility_2t' + str(i)] = dataframe_volatility['volatility'].shift(i+1)\n",
    "            # 根据endtime合并 dataframe    \n",
    "            self.data_record = self.data_record.merge(dataframe_volatility.drop(columns = ['volatility']), on = 'hour_e_time', how = 'inner')\n",
    "        \n",
    "        # 删除缺失值\n",
    "        self.data_record = self.data_record.dropna()\n",
    "    \n",
    "    # 滚动预测模型 来判断阶数好坏 模拟真实市场\n",
    "    # traintime: 训练时间\n",
    "    # pred_length: 预测长度\n",
    "    # order: 每个变量的阶数\n",
    "    # timestep: 每个变量的时间步长 这里timestep[5]是一个list 第一个是zscore的时间步长 第二个是zscore的period\n",
    "    # ma: moving average的阶数\n",
    "    def test_model(self, traintime , pred_length, order, timestep, ma):\n",
    "        # 倒序向前60分钟 作为每个区间的endtime\n",
    "        # 区间长度是60分钟 以小时为单位 \n",
    "        time_range = pd.date_range(start=self.end_time , end=self.start_time, freq = timedelta(minutes = -60))\n",
    "        self.data_laundry = pd.DataFrame({'hour_e_time': time_range})\n",
    "        self.data_laundry.insert(0, 'hour_s_time' , time_range + timedelta(minutes = - 60))\n",
    "        \n",
    "        # 倒序向前 predict length长度 作为每个区间的endtime\n",
    "        # 区间长度是predict length*60分钟 以小时为单位\n",
    "        test_range = pd.date_range(start=self.end_time , end=self.start_time, freq = timedelta(minutes = -60 * pred_length))\n",
    "        test_table = pd.DataFrame({'hour_e_time': test_range})\n",
    "        test_table['hour_s_time'] = test_table['hour_e_time'].shift(-1)\n",
    "        # 去除train time长度的 \n",
    "        test_table = test_table[test_table['hour_s_time'] >= self.start_time + timedelta(minutes = 60 * traintime)]\n",
    "        \n",
    "        # 根据predict length 的starttime得到 train的 endtime\n",
    "        train_table = pd.DataFrame({'hour_e_time': test_table['hour_s_time']})\n",
    "        train_table['hour_s_time'] = train_table['hour_e_time'] - timedelta(minutes = 60 * traintime)\n",
    "        # 多加ma个长度 用来计算error\n",
    "        test_table['hour_s_time'] = test_table['hour_s_time'] - timedelta(minutes = 60 * int(ma))\n",
    "        \n",
    "        # 换成顺序排列\n",
    "        self.data_laundry = self.data_laundry.dropna()[::-1].reset_index(drop=True)\n",
    "        \n",
    "        # 得到相应order和timestep的 变量数据\n",
    "        # highlow_difference(t-n)  highlow(t-n)  volume_sum(t-n)  return_square(t-n)  volatility(t-n)  zscore(t-n)\n",
    "        self.set_data_record(order, timestep)\n",
    "        \n",
    "        # 删除data record中的starttime 用endtime对其数据\n",
    "        data_noma = self.data_record.drop(columns = ['hour_s_time'])\n",
    "        data_noma = data_noma.dropna()\n",
    "\n",
    "        \n",
    "        # 把需要用到的数据加入到data_laundry中 用endtime对其数据\n",
    "        self.data_laundry = self.data_laundry.merge(data_noma, on = 'hour_e_time', how = 'inner')\n",
    "        \n",
    "        # 初始化预测的dataframe\n",
    "        df_pred = pd.DataFrame()\n",
    "        \n",
    "        # 滚动预测\n",
    "        # 以train time为单位 预测下一个predict length长度的volatility\n",
    "        # 用 traintime的数据来得到模型\n",
    "        # 用predict length的数据来预测 根据traintime模型的参数\n",
    "        for i in test_table.index:\n",
    "            # 取出相应的train time和predict length的数据\n",
    "            df_train  = self.dataframe[(self.dataframe.e_date > train_table.hour_s_time[i]) & (self.dataframe.e_date <=  train_table.hour_e_time[i])].copy()\n",
    "            df_test  = data_noma[(data_noma.hour_e_time > test_table.hour_s_time[i]) & (data_noma.hour_e_time <=  test_table.hour_e_time[i])].copy()\n",
    "            # data new用来储存当前loop的预测数据\n",
    "            df_data_new = pd.DataFrame({'hour_e_time': df_test['hour_e_time']})\n",
    "\n",
    "            # 把train time的数据变成class来得到模型\n",
    "            train_object = test()\n",
    "            train_object.set_data_df(df_train)\n",
    "            model = train_object.HLVGARCH_MA(order, timestep, ma)\n",
    "\n",
    "            # 用没有moving average的数据来预测\n",
    "            df_test['predict'] = model[0].predict(sm.add_constant(df_test.drop(columns = ['hour_e_time', 'volatility'])))\n",
    "\n",
    "            # 如果有moving average项\n",
    "            if ma > 0:\n",
    "                # 计算error\n",
    "                df_test['error'] = df_test['volatility'] - df_test['predict']\n",
    "                # 得到t-1, t-2, t-3。。。的error\n",
    "                for j in range(ma):\n",
    "                    df_test['error_t' + str(j)] = df_test['error'].shift(j+1)\n",
    "                    # 加入data new来加入到 predict dataframe中\n",
    "                    df_data_new['error_t' + str(j)] = df_test['error'].shift(j+1) \n",
    "                # 删除缺失值    \n",
    "                df_test = df_test.dropna()\n",
    "                df_data_new = df_data_new.dropna()\n",
    "                # 用带有moving average的参数 来预测\n",
    "                df_test['predict'] = model[1].predict(sm.add_constant(df_test.drop(columns = ['hour_e_time', 'volatility', 'error', 'predict'])))\n",
    "\n",
    "            # 加入预测数据    \n",
    "            df_data_new['predict'] = df_test['predict']\n",
    "            # 更新预测的dataframe\n",
    "            frame = [df_data_new, df_pred]\n",
    "            df_pred = pd.concat(frame)    \n",
    "        \n",
    "        # 加入预测的volatility\n",
    "        self.data_laundry = self.data_laundry.merge(df_pred, on = 'hour_e_time', how = 'inner')\n",
    "        self.data_laundry['real'] = self.data_laundry['volatility']\n",
    "        self.data_laundry = self.data_laundry.drop(columns = ['volatility'])\n",
    "        return self.data_laundry\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_ = 'btc/usdt.spot.binance'\n",
    "# set the start time\n",
    "s_time = datetime.datetime(2024, 1 ,1, 1, 59, 0)\n",
    "# set the end time\n",
    "e_time = datetime.datetime(2024, 6, 1, 1, 59, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour_s_time</th>\n",
       "      <th>hour_e_time</th>\n",
       "      <th>return_square_t0</th>\n",
       "      <th>volatility_t0</th>\n",
       "      <th>predict</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-31 02:00:00</td>\n",
       "      <td>2024-01-31 03:00:00</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.003163</td>\n",
       "      <td>0.004206</td>\n",
       "      <td>0.003291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-31 03:00:00</td>\n",
       "      <td>2024-01-31 04:00:00</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.002447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-31 04:00:00</td>\n",
       "      <td>2024-01-31 05:00:00</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-31 05:00:00</td>\n",
       "      <td>2024-01-31 06:00:00</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.001922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-31 06:00:00</td>\n",
       "      <td>2024-01-31 07:00:00</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>0.001354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>2024-05-31 21:00:00</td>\n",
       "      <td>2024-05-31 22:00:00</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.008243</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.009289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>2024-05-31 22:00:00</td>\n",
       "      <td>2024-05-31 23:00:00</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>0.006549</td>\n",
       "      <td>0.007585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>2024-05-31 23:00:00</td>\n",
       "      <td>2024-06-01 00:00:00</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.004189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>2024-06-01 00:00:00</td>\n",
       "      <td>2024-06-01 01:00:00</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.007886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>2024-06-01 01:00:00</td>\n",
       "      <td>2024-06-01 02:00:00</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.007886</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2928 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             hour_s_time         hour_e_time  return_square_t0  volatility_t0  \\\n",
       "0    2024-01-31 02:00:00 2024-01-31 03:00:00          0.000005       0.003163   \n",
       "1    2024-01-31 03:00:00 2024-01-31 04:00:00          0.000001       0.003291   \n",
       "2    2024-01-31 04:00:00 2024-01-31 05:00:00          0.000013       0.002447   \n",
       "3    2024-01-31 05:00:00 2024-01-31 06:00:00          0.000002       0.005359   \n",
       "4    2024-01-31 06:00:00 2024-01-31 07:00:00          0.000002       0.001922   \n",
       "...                  ...                 ...               ...            ...   \n",
       "2923 2024-05-31 21:00:00 2024-05-31 22:00:00          0.000020       0.008243   \n",
       "2924 2024-05-31 22:00:00 2024-05-31 23:00:00          0.000076       0.009289   \n",
       "2925 2024-05-31 23:00:00 2024-06-01 00:00:00          0.000044       0.007585   \n",
       "2926 2024-06-01 00:00:00 2024-06-01 01:00:00          0.000018       0.004189   \n",
       "2927 2024-06-01 01:00:00 2024-06-01 02:00:00          0.000004       0.007886   \n",
       "\n",
       "       predict      real  \n",
       "0     0.004206  0.003291  \n",
       "1     0.003857  0.002447  \n",
       "2     0.004859  0.005359  \n",
       "3     0.003870  0.001922  \n",
       "4     0.003904  0.001354  \n",
       "...        ...       ...  \n",
       "2923  0.005833  0.009289  \n",
       "2924  0.006549  0.007585  \n",
       "2925  0.005679  0.004189  \n",
       "2926  0.004133  0.007886  \n",
       "2927  0.005603  0.002092  \n",
       "\n",
       "[2928 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = test()\n",
    "data.set_data(s_time, e_time, symbols='btc/usdt.spot.binance', fields=None, bar_type=\"1m\", offset=None, engine_info=None)\n",
    "testdf = data.test_model(24*30, 24, order = [0, 0, 0, 1, 1, 0], timestep = [60, 60, 60, 60, 60, [60, 24]], ma = 0).copy()\n",
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf['predict'] = np.sqrt(testdf['predict'])\n",
    "testdf['real'] = np.sqrt(testdf['real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>return_square_t0</th>\n",
       "      <th>volatility_t0</th>\n",
       "      <th>predict</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>return_square_t0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545081</td>\n",
       "      <td>0.808741</td>\n",
       "      <td>0.472610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatility_t0</th>\n",
       "      <td>0.545081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690748</td>\n",
       "      <td>0.522238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict</th>\n",
       "      <td>0.808741</td>\n",
       "      <td>0.690748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <td>0.472610</td>\n",
       "      <td>0.522238</td>\n",
       "      <td>0.637146</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  return_square_t0  volatility_t0   predict      real\n",
       "return_square_t0          1.000000       0.545081  0.808741  0.472610\n",
       "volatility_t0             0.545081       1.000000  0.690748  0.522238\n",
       "predict                   0.808741       0.690748  1.000000  0.637146\n",
       "real                      0.472610       0.522238  0.637146  1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
